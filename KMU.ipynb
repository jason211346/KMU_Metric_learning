{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "from PIL import Image\n",
    "from tqdm import tqdm \n",
    "# from loss.SoftTriple import SoftTriple\n",
    "from loss.softtriple import SoftTriple\n",
    "import evaluation as eva\n",
    "# import net\n",
    "# from net.bninception import bninception\n",
    "from net.cnn_ensemble import cnn_ensemble\n",
    "from dataset.dataset_kmu_cnn import Dataset\n",
    "# from net.resnet_model import ResNet50\n",
    "# from net.resnet_model_cls import ResNet50\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasettttt = '/root/notebooks/nfs/work/jason.chen/project/siamese-pytorch/dataset/KMU_dataset_512/BF_a_black1'\n",
    "\n",
    "\n",
    "traindir = os.path.join(datasettttt, 'train')\n",
    "testdir = os.path.join(datasettttt, 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset   = Dataset(traindir, shuffle_pairs=True, augment=True)\n",
    "val_dataset     = Dataset(testdir, shuffle_pairs=True, augment=False)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=24,num_workers=8, drop_last=True)\n",
    "val_dataloader   = torch.utils.data.DataLoader(val_dataset, batch_size=6,num_workers=8, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(image1,image2), y, (class1, class2) = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "freeze_BN = True\n",
    "gpu = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1, image2, y = map(lambda x: x.to(gpu), [image1, image2, y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = []\n",
    "IDimg_num = 3\n",
    "for i in range (int(len(y)/IDimg_num)):\n",
    "    yy = y[(IDimg_num*i)]\n",
    "    \n",
    "    if i >0:\n",
    "        label = torch.cat((label,yy),0)\n",
    "    else:\n",
    "        label = yy\n",
    "# label = label.unsqueeze(1)\n",
    "label = label.to(gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = label.to(torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cnn_ensemble()\n",
    "torch.cuda.set_device(0)\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = SoftTriple().cuda()\n",
    "optimizer = torch.optim.Adam([{\"params\": model.parameters(), \"lr\": 0.0001},\n",
    "                              {\"params\": criterion.parameters(), \"lr\": 0.01}],\n",
    "                             eps=0.01, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(image1, image2, batch_size=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 512])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 512])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, preds = criterion(output, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 1, 0, 1, 1, 0, 1], device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1, 1, 0, 0, 1, 0], device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9110, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader,correct,total,running_loss, model, criterion, optimizer,freeze_BN,gpu):\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    if freeze_BN:\n",
    "        for m in model.modules():\n",
    "            if isinstance(m, nn.BatchNorm2d):\n",
    "                m.eval()\n",
    "                \n",
    "    for (img1, img2), y, (class1, class2) in train_loader:\n",
    "        img1, img2, y = map(lambda x: x.to(device), [img1, img2, y])\n",
    "\n",
    "        target = []\n",
    "        IDimg_num = 3\n",
    "        for i in range (int(len(y)/IDimg_num)):\n",
    "            yy = y[(IDimg_num*i)]\n",
    "\n",
    "            if i >0:\n",
    "                target = torch.cat((target,yy),0)\n",
    "            else:\n",
    "                target = yy\n",
    "        target = target.to(device)\n",
    "\n",
    "        output = model(img1, img2, batch_size=24)\n",
    "        loss, preds = criterion(output, label)\n",
    "    \n",
    "#         import pdb; pdb.set_trace()\n",
    "        correct += (preds == target).sum().item()\n",
    "        total += len(target)\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    acc = correct / total\n",
    "    train_epoch_loss = running_loss / len(train_loader)\n",
    "    \n",
    "    print('train_acc : ',acc ,'  train_loss : ',train_epoch_loss)\n",
    "    return acc , train_epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(test_loader,correct,total,running_loss, model,criterion,gpu):\n",
    "    # switch to evaluation mode\n",
    "    model.eval()\n",
    "    testdata = torch.Tensor()\n",
    "    testlabel = torch.LongTensor()\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(test_loader):\n",
    "            if gpu is not None:\n",
    "                input = input.cuda(gpu, non_blocking=True)\n",
    "                target = target.cuda(gpu, non_blocking=True)\n",
    "            # compute output\n",
    "            output = model(input)\n",
    "            #         loss = criterion(output, target)\n",
    "            loss, preds = criterion(output, target)\n",
    "            correct += (preds == target).sum().item()\n",
    "            total += len(target)\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            testdata = torch.cat((testdata, output.cpu()), 0)\n",
    "            testlabel = torch.cat((testlabel, target.cpu()))\n",
    "            \n",
    "        for (img1, img2), y, (class1, class2) in test_loader:\n",
    "            img1, img2, y = map(lambda x: x.to(device), [img1, img2, y])\n",
    "\n",
    "            target = []\n",
    "            IDimg_num = 3\n",
    "            for i in range (int(len(y)/IDimg_num)):\n",
    "                yy = y[(IDimg_num*i)]\n",
    "\n",
    "                if i >0:\n",
    "                    target = torch.cat((target,yy),0)\n",
    "                else:\n",
    "                    target = yy\n",
    "            target = target.to(device)\n",
    "\n",
    "            output = model(img1, img2, batch_size = args.epochs)\n",
    "            loss, preds = criterion(output, label)\n",
    "            correct += (preds == target).sum().item()\n",
    "            total += len(target)\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            testdata = torch.cat((testdata, output.cpu()), 0)\n",
    "            testlabel = torch.cat((testlabel, target.cpu()))\n",
    "            \n",
    "    val_epoch_loss = running_loss / len(test_loader)\n",
    "    val_acc = correct / total\n",
    "    print('val_acc : ',val_acc, 'val_loss : ',val_epoch_loss)\n",
    "    nmi, recall = eva.evaluation(testdata.numpy(), testlabel.numpy(), [1, 2, 4, 8])\n",
    "    return nmi, recall , val_acc, val_epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    # decayed lr by 10 every 20 epochs\n",
    "    if (epoch+1)%20 == 0:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] *= 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss_list=[]\n",
    "train_loss_list=[]\n",
    "val_acc_list=[]\n",
    "train_acc_list=[]\n",
    "out_path = '/root/notebooks/nfs/work/jason.chen/project/triplet_loss/pytorch-triplet-loss/SoftTriple/out_model/KMU'\n",
    "#--train\n",
    "for epoch in range(0, 5):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0.0\n",
    "    print('Training in Epoch[{}]'.format(epoch))\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "    # train for one epoch\n",
    "    train_acc, train_loss = train(train_loader, correct,total,running_loss,model, criterion, optimizer,freeze_BN,gpu)\n",
    "\n",
    "    train_loss_list.append(train_loss)\n",
    "    train_acc_list.append(train_acc)\n",
    "\n",
    "# evaluate on validation set\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0.0\n",
    "    nmi, recall ,val_acc , val_loss= validate(test_loader,correct,total,running_loss, model,criterion,gpu)\n",
    "\n",
    "    val_acc_list.append(val_acc)\n",
    "    val_loss_list.append(val_loss)\n",
    "#--save final model \n",
    "plt.plot(val_loss_list, label='val_loss')\n",
    "plt.plot(train_loss_list, label='train_loss')\n",
    "plt.legend()\n",
    "plt.title('training loss and val loss')\n",
    "plt.savefig(os.path.join(out_path+'KMU', 'loss.png'))\n",
    "plt.cla()\n",
    "plt.plot(val_acc_list, label='val_acc')\n",
    "plt.plot(train_acc_list, label='train_acc')\n",
    "plt.legend()\n",
    "plt.title('training acc and val acc')\n",
    "plt.savefig(os.path.join(out_path+'KMU', 'acc.png'))\n",
    "\n",
    "torch.save(\n",
    "            {\n",
    "                \"epoch\": epoch + 1,\n",
    "                \"model_state_dict\": model.state_dict(),\n",
    "                \"optimizer_state_dict\": optimizer.state_dict()\n",
    "            },\n",
    "            os.path.join(out_path+'KMU', 'KMU'+'.pth')\n",
    "        )   \n",
    "print('Recall@1, 2, 4, 8: {recall[0]:.3f}, {recall[1]:.3f}, {recall[2]:.3f}, {recall[3]:.3f}; NMI: {nmi:.3f} \\n'\n",
    "                  .format(recall=recall, nmi=nmi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8682,  0.2698, -0.1919,  0.8682,  0.2698, -0.1919],\n",
       "        [-1.2108,  0.0146, -0.1874, -1.2108,  0.0146, -0.1874]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2, 3)\n",
    "torch.cat((x, x), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(1, len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
